# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
- master

pool:
  vmImage: ubuntu-latest
strategy:
  matrix:
    Python37:
      python.version: '3.7'

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: '$(python.version)'
  displayName: 'Use Python $(python.version)'

- script: |
    python -m pip install --upgrade pip
  displayName: 'Install dependencies'


  
- task: Bash@3
  inputs:
    targetType: 'inline'
    script: |
      echo 'retrieve git log'
      git log -100 >$(Build.BinariesDirectory)/git_log.txt


- script: |
    pip install pytest pytest-azurepipelines
    
  displayName: 'python auth'      

- task: PythonScript@0
  inputs:
    scriptSource: 'inline'
    script: |
      import json
                  
          with open('$(Build.BinariesDirectory)/git_log.txt', 'r', encoding='utf-8') as f:
              line = f.readline()
              commits = []
              comments = ''
              id, author, date = None, None, None
              # import pdb; pdb.set_trace();
              while line:
                  line = line.strip()
                  if not (line.startswith('commit') \
                  or line.startswith('Author') \
                  or line.startswith('Date')):
                      line = f.readline()
                      comments += line
                      continue
                  if line.startswith('commit'):
                      id = line.split(' ')[-1]
                  if line.startswith('Author'):
                      author = line.split(' ')[-1]
                  if line.startswith('Date'):
                      date = line.split('Date:')[-1].strip()
                  if id and author and date and comments:
                      commits.append({
                          'id': id,
                          'owner': author,
                          'date': date,
                          'comments': comments
                      })
                      comments = ''
                      id, author, date = None, None, None
                  line = f.readline()
      
              print(commits[0])
              with open('$(Build.BinariesDirectory)/git_log.json', 'w', encoding='utf-8') as f:
                  f.write(json.dumps(commits,separators=(',', ':'), indent=4))
- task: ArchiveFiles@2

  inputs:
    rootFolderOrFile: '$(Build.BinariesDirectory)'
    includeRootFolder: true
    archiveType: 'zip'
    archiveFile: '$(Build.ArtifactStagingDirectory)/$(Build.BuildId).zip'
    replaceExistingArchive: true
- task: PublishBuildArtifacts@1
  inputs:
    PathtoPublish: '$(Build.ArtifactStagingDirectory)'
    ArtifactName: 'drop'
    publishLocation: 'Container'